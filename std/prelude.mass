// `__get` is a global because it itself needs to be used to access module exports
operator(.) :: 20 __get

// `__import` is global to avoid the need to define other compiler exports as global
operator(import _) :: 20 __import

MASS :: import("mass")

// These keyword-like operators have extremely high precedence to make sure that
// they really get the next token, unless the user has something really specific
// in mind and creates an operator with an even higher precedence.
operator(module _) :: 100 MASS.inline_module
operator(intrinsic _) :: 100 MASS.intrinsic
operator(c_struct _) :: 100 MASS.c_struct
operator(exports _) :: 100 MASS.exports

// `using` and `return` want an arbitrary expression so have the lowest precedence
operator(using _) :: 0 MASS.using
operator(return _) :: 0 MASS.return

// `size_of` and `type_of` are essentially function calls with special parsing
// rules and evaluation behavior, so they get the same precedence as `apply`
operator(type_of _) :: 20 MASS.type_of
operator(size_of _) :: 20 MASS.size_of

operator(' _) :: 30 MASS.quote
operator(_ ') :: 30 MASS.unquote

operator(,) :: 0 MASS.comma

// TODO allow non-intrinsic overloads
operator(=) :: 1 MASS.assign
operator(:=) :: 0 MASS.define_inferred
operator(_ .*) :: 20 MASS.dereference

operator(:) :: 2 MASS.typed_symbol

operator(@ _) :: 20 MASS.eval
operator(. _) :: 30 MASS.named_accessor

operator(==) :: 7 'equal
operator(!=) :: 7 'not_equal

operator(<) :: 8 'less
operator(>) :: 8 'greater
operator(<=) :: 8 'less_equal
operator(>=) :: 8 'greater_equal

operator(+) :: 10 'add
operator(-) :: 10 'subtract

operator(*) :: 15 'multiply
operator(/) :: 15 'divide
operator(%) :: 15 'remainder

operator(<<) :: 15 'logical_shift_left
operator(>>) :: 15 'logical_shift_right
operator(|) :: 15 'bitwise_or
operator(&) :: 15 'bitwise_and

operator(- _) :: 16 'negate
operator(& _) :: 16 'pointer_to

postfix_block :: fn(
  header : MASS.Function_Header,
  block : MASS.Ast_Block
) => (MASS.Function_Literal) MASS.function_literal

cast :: fn(type : Type, value) -> _ MASS.cast
zero_extend :: fn(type : Type, value) -> _ MASS.zero_extend

is_integer_type :: MASS.constraint_integer_type
is_float_type :: MASS.constraint_float_type
is_pointer_type :: MASS.constraint_pointer_type
is_fixed_array_type :: MASS.constraint_fixed_array_type
is_struct_type :: MASS.constraint_struct_type
is_function_instance_type :: MASS.constraint_function_instance_type

string_get :: fn(string : String, offset : i64) => (i8) {
  using unsigned
  assert(offset < string.length);
  unchecked_get_at_index(string.bytes, offset)
}

// TODO runtime version should be implemented in the userland
unchecked_get_at_index :: fn(
  x ~ is_pointer_type,
  offset : i64
) -> ((x.*).Pointer_To.descriptor) MASS.unchecked_get_at_index
unchecked_get_at_index :: fn(
  x ~ is_pointer_type,
  offset : i64
) => ((x.*).Pointer_To.descriptor) MASS.unchecked_get_at_index

get :: fn(x ~ is_struct_type, rhs) -> _ MASS.struct_get
get :: fn(x ~ is_fixed_array_type, rhs) -> _ MASS.unchecked_get_at_index

// Auto-dereferencing pointers. This is a very generic fn, meaning that a user can easily
// create a more specic overload even for pointer types.
get :: fn(x ~ is_pointer_type, rhs) -> _ intrinsic {
  sliced_args := arguments
  sliced_args.length = cast(i32, 1)
  deref := MASS.dereference(context, parser, sliced_args)
  arguments.values.* = deref
  __get(context, parser, arguments)
}

Void :: type_of(())
make_void :: fn(allocator : &Allocator, source_range : &MASS.Source_Range) -> (&MASS.Value) {
  value : &MASS.Value = allocate(allocator, MASS.Value)
  value.source_range = source_range.*
  value.tag = MASS.Value_Tag.Forced
  value.descriptor = Void
  value.Forced.storage.tag = MASS.Storage_Tag.Immediate
  value.Forced.storage.bit_size = [0]
  value
}

debugger :: fn() -> () intrinsic {
  lazy_value_proc :: fn(
    context : &MASS.Context,
    builder : &MASS.Function_Builder,
    expected_result : &MASS.Expected_Result,
    source_range : &MASS.Source_Range,
    payload : &Void
  ) -> (&MASS.Value) {
    {
      instruction : MASS.Instruction
      instruction.tag = MASS.Instruction_Tag.Location
      instruction.Location.source_range = source_range.*
    }

    {
      instruction : MASS.Instruction
      instruction.tag = MASS.Instruction_Tag.Bytes
      instruction.Bytes.memory.0 = cast(i8, 0xcc)
      instruction.Bytes.length = cast(i8, 1)
      MASS.push_instruction(&builder.code_block, instruction);
    }

    make_void(context.allocator, source_range)
  }

  lazy_value := allocate(context.allocator, MASS.Value)
  lazy_value.tag = MASS.Value_Tag.Lazy
  lazy_value.descriptor = Void
  lazy_value.source_range = arguments.source_range
  lazy_value.Lazy = [.epoch = parser.epoch, .proc = lazy_value_proc, .payload = 0]

  lazy_value
}

true :: cast(bool, 1)
false :: cast(bool, 0)

assert :: fn(condition : bool, message := "Assertion failed\n") -> () {
  // TODO add something like MASS.intrinsic_assert or MASS.intrinsic_print
  //      that would be safe to call without a risk or circular dependencies
  // TODO also detect these kind of dependencies better
  //io :: import("std/io")
  if condition then {} else {
    //io.print(message)
    debugger()
  }
}
get :: fn(view : MASS.Value_View, index : i64) -> (&MASS.Value) {
  assert(MASS.i64_unsigned_less_equal(index, 0xFFFF_FFFF))
  unchecked_get_at_index(view.values, index)
}

static_assert :: fn(condition : bool, message : String = "") => () MASS.static_assert

pointer_to :: fn(type : Type) => (Type) MASS.pointer_to_type
pointer_to :: fn(x) -> (pointer_to(x)) MASS.pointer_to

MASS_I64_MATH :: module {
  add :: MASS.i64_add
  subtract :: MASS.i64_subtract
  signed_multiply :: MASS.i64_signed_multiply
  unsigned_multiply :: MASS.i64_unsigned_multiply
  signed_divide :: MASS.i64_signed_divide
  unsigned_divide :: MASS.i64_unsigned_divide
  signed_remainder :: MASS.i64_signed_remainder
  unsigned_remainder :: MASS.i64_unsigned_remainder

  signed_less :: MASS.i64_signed_less
  unsigned_less :: MASS.i64_unsigned_less
  signed_less_equal :: MASS.i64_signed_less_equal
  unsigned_less_equal :: MASS.i64_unsigned_less_equal
  signed_greater :: MASS.i64_signed_greater
  unsigned_greater :: MASS.i64_unsigned_greater
  signed_greater_equal :: MASS.i64_signed_greater_equal
  unsigned_greater_equal :: MASS.i64_unsigned_greater_equal

  negate :: fn(x : i64) -> (i64) { MASS.i64_subtract(0, x) }

  logical_shift_left :: MASS.i64_logical_shift_left
  logical_shift_right :: MASS.i64_logical_shift_right
  bitwise_or :: MASS.i64_bitwise_or
  bitwise_and :: MASS.i64_bitwise_and
}


add :: fn(x : i64, y : i64) => (i64) { MASS.i64_add(x, y) }
subtract :: fn(x : i64, y : i64) => (i64) { MASS.i64_subtract(x, y) }
signed_multiply :: fn(x : i64, y : i64) => (i64) { MASS.i64_signed_multiply(x, y) }
unsigned_multiply :: fn(x : i64, y : i64) => (i64) { MASS.i64_unsigned_multiply(x, y) }
signed_divide :: fn(x : i64, y : i64) => (i64) { MASS.i64_signed_divide(x, y) }
unsigned_divide :: fn(x : i64, y : i64) => (i64) { MASS.i64_unsigned_divide(x, y) }
signed_remainder :: fn(x : i64, y : i64) => (i64) { MASS.i64_signed_remainder(x, y) }
unsigned_remainder :: fn(x : i64, y : i64) => (i64) { MASS.i64_unsigned_remainder(x, y) }

signed_less :: fn(x : i64, y : i64) => (bool) { MASS.i64_signed_less(x, y) }
unsigned_less :: fn(x : i64, y : i64) => (bool) { MASS.i64_unsigned_less(x, y) }
signed_less_equal :: fn(x : i64, y : i64) => (bool) { MASS.i64_signed_less_equal(x, y) }
unsigned_less_equal :: fn(x : i64, y : i64) => (bool) { MASS.i64_unsigned_less_equal(x, y) }
signed_greater :: fn(x : i64, y : i64) => (bool) { MASS.i64_signed_greater(x, y) }
unsigned_greater :: fn(x : i64, y : i64) => (bool) { MASS.i64_unsigned_greater(x, y) }
signed_greater_equal :: fn(x : i64, y : i64) => (bool) { MASS.i64_signed_greater_equal(x, y) }
unsigned_greater_equal :: fn(x : i64, y : i64) => (bool) { MASS.i64_unsigned_greater_equal(x, y) }

negate :: fn(x : i64) => (i64) { MASS.i64_subtract(0, x) }

logical_shift_left :: fn(x : i64, y : i64) => (i64) { MASS.i64_logical_shift_left(x, y) }
logical_shift_right :: fn(x : i64, y : i64) => (i64) { MASS.i64_logical_shift_right(x, y) }
bitwise_or :: fn(x : i64, y : i64) => (i64) { MASS.i64_bitwise_or(x, y) }
bitwise_and :: fn(x : i64, y : i64) => (i64) { MASS.i64_bitwise_and(x, y) }

make_arithmetic_operations_module :: macro(type : Type) {
  module {
    add :: fn(x : type, y : type) -> (type) MASS.integer_add
    subtract :: fn(x : type, y : type) -> (type) MASS.integer_subtract
    multiply :: fn(x : type, y : type) -> (type) MASS.integer_multiply
    divide :: fn(x : type, y : type) -> (type) MASS.integer_divide
    remainder :: fn(x : type, y : type) -> (type) MASS.integer_remainder
    negate :: fn(x : type) -> (type) { 0 - x }

    less :: fn(x : type, y : type) -> (bool) MASS.integer_less
    less_equal :: fn(x : type, y : type) -> (bool) MASS.integer_less_equal
    greater :: fn(x : type, y : type) -> (bool) MASS.integer_greater
    greater_equal :: fn(x : type, y : type) -> (bool) MASS.integer_greater_equal
    equal :: fn(x : type, y : type) -> (bool) MASS.integer_equal
    not_equal :: fn(x : type, y : type) -> (bool) MASS.integer_not_equal
  }
}

using make_arithmetic_operations_module(s8)
using make_arithmetic_operations_module(s16)
using make_arithmetic_operations_module(s32)
using make_arithmetic_operations_module(s64)
using make_arithmetic_operations_module(u8)
using make_arithmetic_operations_module(u16)
using make_arithmetic_operations_module(u32)
using make_arithmetic_operations_module(u64)

x86_64 :: module {
  REX_B :: 0b0001 // Extension of the ModR/M r/m field, SIB base field, or Opcode reg field
  REX_X :: 0b0010 // Extension of the SIB index field
  REX_R :: 0b0100 // Extension of the ModR/M reg field
  REX_W :: 0b1000 // 0 = Storage size determined by CS.D; 1 = 64 Bit Storage Size

  Register :: MASS.Register
  Instruction :: MASS.Instruction

  op1_reg64_reg64_mr :: fn(op_code : i8, target : Register, source : Register) -> (Instruction) {
    using MASS_I64_MATH

    lhs_reg_index := zero_extend(i64, target)
    rhs_reg_index := zero_extend(i64, source)

    rex := 0x40 + REX_W
    rex = if lhs_reg_index & 0b1000 != 0 then rex + REX_B else rex
    rex = if rhs_reg_index & 0b1000 != 0 then rex + REX_R else rex

    mod_reg_rm := cast(i8, (0b11 << 6) | ((rhs_reg_index & 0b111) << 3) | (lhs_reg_index & 0b111))

    instruction : Instruction
    instruction.tag = MASS.Instruction_Tag.Bytes
    instruction.Bytes.memory.0 = cast(i8, rex)
    instruction.Bytes.memory.1 = op_code
    instruction.Bytes.memory.2 = cast(i8, mod_reg_rm)
    instruction.Bytes.length = cast(i8, 3)
    instruction
  }
}

add_or_subtract :: fn(
  context : &MASS.Context,
  parser : &MASS.Parser,
  arguments : MASS.Value_View,
  op_code : i8
) -> (&MASS.Value) {
  meta :: import("std/meta")

  Payload :: c_struct [ lhs : &MASS.Value, rhs : &MASS.Value, op_code : i8 ]

  lazy_value_proc :: fn(
    context : &MASS.Context,
    builder : &MASS.Function_Builder,
    expected_result : &MASS.Expected_Result,
    source_range : &MASS.Source_Range,
    raw_payload : &Void
  ) -> (&MASS.Value) {
    payload := cast(&Payload, raw_payload)
    temp_lhs_storage := MASS.storage_register_temp(builder, [64]);
    temp_lhs_register := temp_lhs_storage.Register.index
    expected_lhs := MASS.expected_result_exact(i64, temp_lhs_storage)

    temp_lhs := MASS.value_force(context, builder, &expected_lhs, payload.lhs)

    if context.compilation.result.tag != MASS.Result_Tag.Success then {
      return 0
    }

    temp_rhs_storage := MASS.storage_register_temp(builder, [64]);
    temp_rhs_register := temp_rhs_storage.Register.index
    expected_rhs := MASS.expected_result_exact(i64, temp_rhs_storage)

    temp_rhs := MASS.value_force(context, builder, &expected_rhs, payload.rhs)

    if context.compilation.result.tag != MASS.Result_Tag.Success then {
      return 0
    }

    {
      instruction : MASS.Instruction
      instruction.tag = MASS.Instruction_Tag.Location
      instruction.Location.source_range = source_range.*
    }

    {
      instruction := x86_64.op1_reg64_reg64_mr(payload.op_code, temp_lhs_register, temp_rhs_register)
      MASS.push_instruction(&builder.code_block, instruction);
    }

    MASS.register_release(builder, temp_rhs_register);

    temp_lhs
  }

  payload := allocate(context.allocator, Payload)
  payload.* = [arguments.0, arguments.1, op_code]

  lazy_value := allocate(context.allocator, MASS.Value)
  lazy_value.tag = MASS.Value_Tag.Lazy
  lazy_value.descriptor = i64
  lazy_value.source_range = arguments.source_range
  lazy_value.Lazy = [.epoch = parser.epoch, .proc = lazy_value_proc, .payload]

  lazy_value
}

add :: fn(x : i64, y : i64) -> (i64) intrinsic {
  add_or_subtract(context, parser, arguments, cast(i8, 0x01))
}

subtract :: fn(x : i64, y : i64) -> (i64) intrinsic {
  add_or_subtract(context, parser, arguments, cast(i8, 0x29))
}

compare :: fn(
  context : &MASS.Context,
  parser : &MASS.Parser,
  arguments : MASS.Value_View,
  compare_type : MASS.Compare_Type
) -> (&MASS.Value) {
  meta :: import("std/meta")

  Payload :: c_struct [ lhs : &MASS.Value, rhs : &MASS.Value, compare_type : MASS.Compare_Type ]

  lazy_value_proc :: fn(
    context : &MASS.Context,
    builder : &MASS.Function_Builder,
    expected_result : &MASS.Expected_Result,
    source_range : &MASS.Source_Range,
    raw_payload : &Void
  ) -> (&MASS.Value) {
    payload := cast(&Payload, raw_payload)

    temp_lhs_storage := MASS.storage_register_temp(builder, [64]);
    temp_lhs_register := temp_lhs_storage.Register.index
    expected_lhs := MASS.expected_result_exact(i64, temp_lhs_storage)
    temp_lhs := MASS.value_force(context, builder, &expected_lhs, payload.lhs)

    if context.compilation.result.tag != MASS.Result_Tag.Success then {
      return 0
    }

    temp_rhs_storage := MASS.storage_register_temp(builder, [64]);
    temp_rhs_register := temp_rhs_storage.Register.index
    expected_rhs := MASS.expected_result_exact(i64, temp_rhs_storage)
    temp_rhs := MASS.value_force(context, builder, &expected_rhs, payload.rhs)

    if context.compilation.result.tag != MASS.Result_Tag.Success then {
      return 0
    }

    {
      instruction : MASS.Instruction
      instruction.tag = MASS.Instruction_Tag.Location
      instruction.Location.source_range = source_range.*
    }

    {
      instruction := x86_64.op1_reg64_reg64_mr(cast(i8, 0x39), temp_lhs_register, temp_rhs_register)
      MASS.push_instruction(&builder.code_block, instruction)
    }

    MASS.register_release(builder, temp_rhs_register)
    MASS.register_release(builder, temp_lhs_register)

    value : &MASS.Value = allocate(context.allocator, MASS.Value)
    value.tag = MASS.Value_Tag.Forced
    value.source_range = source_range.*
    value.descriptor = bool
    value.Forced.storage.tag = MASS.Storage_Tag.Eflags
    value.Forced.storage.bit_size = (value.descriptor.*).bit_size
    value.Forced.storage.Eflags.compare_type = payload.compare_type
    value
  }

  payload := allocate(context.allocator, Payload)
  payload.* = [arguments.0, arguments.1, compare_type]

  lazy_value := allocate(context.allocator, MASS.Value)
  lazy_value.tag = MASS.Value_Tag.Lazy
  lazy_value.descriptor = bool
  lazy_value.source_range = arguments.source_range
  lazy_value.Lazy = [.epoch = parser.epoch, .proc = lazy_value_proc, .payload]

  lazy_value
}

make_i64_comparison_fn :: macro(compare_type) {
  fn(x : i64, y : i64) -> (bool) intrinsic {
    compare(context, parser, arguments, compare_type)
  }
}

unsigned_less :: make_i64_comparison_fn(MASS.Compare_Type.Unsigned_Below)
unsigned_less_equal :: make_i64_comparison_fn(MASS.Compare_Type.Unsigned_Below_Equal)
unsigned_greater :: make_i64_comparison_fn(MASS.Compare_Type.Unsigned_Above)
unsigned_greater_equal :: make_i64_comparison_fn(MASS.Compare_Type.Unsigned_Above_Equal)

signed_less :: make_i64_comparison_fn(MASS.Compare_Type.Less)
signed_less_equal :: make_i64_comparison_fn(MASS.Compare_Type.Less_Equal)
signed_greater :: make_i64_comparison_fn(MASS.Compare_Type.Greater)
signed_greater_equal :: make_i64_comparison_fn(MASS.Compare_Type.Greater_Equal)

unsigned :: module {
  less :: unsigned_less
  less_equal :: unsigned_less_equal
  greater :: unsigned_greater
  greater_equal :: unsigned_greater_equal
}

signed :: module {
  less :: signed_less
  less_equal :: signed_less_equal
  greater :: signed_greater
  greater_equal :: signed_greater_equal
}

equal :: fn(x, accessor : MASS.Named_Accessor) -> _ intrinsic {
  meta :: import("std/meta")
  accessor := meta.reify(arguments.1, MASS.Named_Accessor)
  x_descriptor := arguments.0.descriptor
  named_value := MASS.module_get(context, (x_descriptor.*).own_module, accessor.symbol, &arguments.source_range)
  values : (&MASS.Value) * 2 = [arguments.0, named_value]
  new_args : MASS.Value_View = arguments
  new_args.values = &values
  MASS.forward_call_to_alias(context, parser, new_args, & 'equal)
}

equal :: fn(x, y : x) -> (bool) MASS.generic_equal
not_equal :: fn(x, y : x) -> (bool) MASS.generic_not_equal
equal :: fn(x, y : x) => (bool) { equal(x, y) }
not_equal :: fn(x, y : x) => (bool) { not_equal(x, y) }

using {
  Bits :: MASS.Bits

  module {
    // FIXME there should be better way to provide conversions
    //       instead of combinatorial explosion of overloads

    // It is is bit awkward that the field is called `as_u64` but the type is actually `i64`
    less :: fn(x : Bits, y : Bits) => (bool) { unsigned_less(x.as_u64, y.as_u64) }
    less :: fn(x : Bits, y : i64) => (bool) { unsigned_less(x.as_u64, y) }
    less :: fn(x : i64, y : Bits) => (bool) { unsigned_less(x, y.as_u64) }

    less_equal :: fn(x : Bits, y : Bits) => (bool) { unsigned_less_equal(x.as_u64, y.as_u64) }
    less_equal :: fn(x : Bits, y : i64) => (bool) { unsigned_less_equal(x.as_u64, y) }
    less_equal :: fn(x : i64, y : Bits) => (bool) { unsigned_less_equal(x, y.as_u64) }

    greater :: fn(x : Bits, y : Bits) => (bool) { unsigned_greater(x.as_u64, y.as_u64) }
    greater :: fn(x : Bits, y : i64) => (bool) { unsigned_greater(x.as_u64, y) }
    greater :: fn(x : i64, y : Bits) => (bool) { unsigned_greater(x, y.as_u64) }

    greater_equal :: fn(x : Bits, y : Bits) => (bool) { unsigned_greater_equal(x.as_u64, y.as_u64) }
    greater_equal :: fn(x : Bits, y : i64) => (bool) { unsigned_greater_equal(x.as_u64, y) }
    greater_equal :: fn(x : i64, y : Bits) => (bool) { unsigned_greater_equal(x, y.as_u64) }
  }
}

Allocator :: MASS.Allocator

allocate :: macro(allocator : &MASS.Allocator, type : Type) {
  cast(&type, MASS.allocator_allocate_bytes(
    allocator,
    MASS.i64_unsigned_divide((type.*).bit_size.as_u64, 8),
    MASS.i64_unsigned_divide((type.*).bit_alignment.as_u64, 8)
  ))
}

Array :: fn(item_type : Type, length : i64) => (Type) intrinsic {
  using MASS_I64_MATH
  meta :: import("std/meta")
  item_type := meta.reify(arguments.0, Type).*
  length := meta.reify(arguments.1, i64).*
  t := allocate(context.allocator, MASS.Descriptor)

  raw_bit_size : i64 = unsigned_multiply((item_type.*).bit_size.as_u64, length)
  if raw_bit_size & 0xffff_ffff_8000_0000 != 0 then {
    error : MASS.Error
    error.tag = MASS.Error_Tag.Integer_Range
    error.source_range = arguments.source_range
    meta.context_error(context, error)
    return 0
  }

  t.* = [
    .tag = MASS.Descriptor_Tag.Fixed_Array,
    .brand = 0,
    .own_module = 0,
    .bit_size = [raw_bit_size],
    .bit_alignment = (item_type.*).bit_alignment,
    .Fixed_Array = [item_type, length]
  ]

  meta.immediate(context.compilation, t, arguments.source_range)
}

multiply :: Array

external :: fn(
  library_name : String,
  symbol_name : String
) => (MASS.External_Symbol) {
  [library_name, symbol_name]
}

os :: MASS.Os
get_target_os :: fn() -> (os) intrinsic {
  meta :: import("std/meta")
  meta.immediate(context.compilation, context.program.os, arguments.source_range)
}

syscall :: fn(number : i64) => (MASS.Syscall) { [number] }

