/* Generated by re2c */
#line 1 "tokenizer.re.c"
// If you want to make changes to the tokenizer, edit tokenizer.re.c
// and then regenerate this file on a Linux machine / WSL:
//
// re2c tokenizer.re.c -o generated_tokenizer.c --no-version --no-generation-date
//
#include "types.h"

PRELUDE_NO_DISCARD Mass_Result
tokenize(
  Mass_Context *context,
  Source_Range source_range,
  Array_Value_View *out_statements
) {
  Compilation *compilation = context->compilation;
  Slice input = source_range.file->text;

  const Allocator *allocator = compilation->allocator;

  Array_Value_Ptr stack = dyn_array_make(Array_Value_Ptr, .capacity = 100);
  Array_Tokenizer_Parent parent_stack =
    dyn_array_make(Array_Tokenizer_Parent, .capacity = 16);

  Mass_Result result = {.tag = Mass_Result_Tag_Success};

  Fixed_Buffer *string_buffer = fixed_buffer_make(.capacity = 4096);

  u64 offset = source_range.offsets.from;
  u64 token_start_offset = offset;
  u64 marker = offset;
  u64 end_offset = source_range.offsets.to;

  #define TOKENIZER_CURRENT_RANGE()\
    (Source_Range){\
      .file = source_range.file,\
      .offsets = {\
        .from = u64_to_u32(token_start_offset),\
        .to = u64_to_u32(offset),\
      }\
    }

  // Create top-level block
  tokenizer_group_start_curly(
    allocator, &stack, &parent_stack, &descriptor_group_curly, TOKENIZER_CURRENT_RANGE()
  );

  #define TOKENIZER_CURRENT_SLICE()\
    slice_sub(input, token_start_offset, offset)

  #define TOKENIZER_PUSH_LITERAL(_BASE_, _SLICE_)\
    dyn_array_push(stack, \
      value_i64(allocator, (_SLICE_), (_BASE_), TOKENIZER_CURRENT_RANGE())\
    )

  #define TOKENIZER_HANDLE_ERROR(_EXPECTED_SLICE_)\
    do {\
      result = (Mass_Result) {\
        .tag = Mass_Result_Tag_Error,\
        .Error.error = {\
          .tag = Mass_Error_Tag_Unexpected_Token,\
          .Unexpected_Token = { .expected = (_EXPECTED_SLICE_), },\
          .source_range = {\
            .file = source_range.file,\
            .offsets = {.from = u64_to_u32(offset) - 1, .to = u64_to_u32(offset) - 1},\
          }\
        }\
      };\
      goto defer;\
    } while (0)

  #define TOKENIZER_PUSH_SYMBOL(_TYPE_)\
    dyn_array_push(stack, \
      token_make_symbol_value(\
        context, TOKENIZER_CURRENT_SLICE(), TOKENIZER_CURRENT_RANGE()\
      )\
    )

  #define TOKENIZER_GROUP_START(_VARIANT_)\
    tokenizer_group_start(\
      allocator, &stack, &parent_stack, &descriptor_group_##_VARIANT_, TOKENIZER_CURRENT_RANGE()\
    )

  #define TOKENIZER_GROUP_END(_VARIANT_)\
    if (!tokenizer_group_end_##_VARIANT_(context, &stack, &parent_stack, offset))\
      TOKENIZER_HANDLE_ERROR((Slice){0})

  for (;;) {
    token_start_offset = offset;
    
#line 92 "generated_tokenizer.c"
{
  char yych;
  unsigned int yyaccept = 0;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '\t':
  case '\v':
  case ' ':  goto yy4;
  case '\n':
  case ';':  goto yy7;
  case '\r':  goto yy9;
  case '!':
  case '$':
  case '%':
  case '&':
  case '*':
  case '+':
  case ',':
  case '-':
  case '.':
  case ':':
  case '<':
  case '=':
  case '>':
  case '?':
  case '@':
  case '\\':
  case '^':
  case '|':
  case '~':  goto yy10;
  case '"':  goto yy13;
  case '\'':  goto yy14;
  case '(':  goto yy15;
  case ')':  goto yy17;
  case '/':  goto yy19;
  case '0':  goto yy20;
  case '1':
  case '2':
  case '3':
  case '4':
  case '5':
  case '6':
  case '7':
  case '8':
  case '9':  goto yy22;
  case 'A':
  case 'B':
  case 'C':
  case 'D':
  case 'E':
  case 'F':
  case 'G':
  case 'H':
  case 'I':
  case 'J':
  case 'K':
  case 'L':
  case 'M':
  case 'N':
  case 'O':
  case 'P':
  case 'Q':
  case 'R':
  case 'S':
  case 'T':
  case 'U':
  case 'V':
  case 'W':
  case 'X':
  case 'Y':
  case 'Z':
  case '_':
  case 'a':
  case 'b':
  case 'c':
  case 'd':
  case 'e':
  case 'f':
  case 'g':
  case 'h':
  case 'i':
  case 'j':
  case 'k':
  case 'l':
  case 'm':
  case 'n':
  case 'o':
  case 'p':
  case 'q':
  case 'r':
  case 's':
  case 't':
  case 'u':
  case 'v':
  case 'w':
  case 'x':
  case 'y':
  case 'z':  goto yy24;
  case '[':  goto yy27;
  case ']':  goto yy29;
  case '{':  goto yy31;
  case '}':  goto yy33;
  default:
    if (offset >= end_offset) goto yy54;
    goto yy2;
  }
yy2:
  ++offset;
yy3:
#line 161 "tokenizer.re.c"
  { TOKENIZER_HANDLE_ERROR((Slice){0}); }
#line 204 "generated_tokenizer.c"
yy4:
  yyaccept = 0;
  ++offset;
  marker = offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '\t':
  case '\v':
  case ' ':  goto yy4;
  case '/':  goto yy35;
  default:  goto yy6;
  }
yy6:
#line 155 "tokenizer.re.c"
  { continue; }
#line 220 "generated_tokenizer.c"
yy7:
  ++offset;
yy8:
#line 140 "tokenizer.re.c"
  {
        tokenizer_maybe_push_statement(context, &stack, &parent_stack, offset - 1);
        continue;
      }
#line 229 "generated_tokenizer.c"
yy9:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '\n':  goto yy7;
  default:  goto yy8;
  }
yy10:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
yy11:
  switch (yych) {
  case '!':
  case '$':
  case '%':
  case '&':
  case '*':
  case '+':
  case ',':
  case '-':
  case '.':
  case '/':
  case ':':
  case '<':
  case '=':
  case '>':
  case '?':
  case '@':
  case '\\':
  case '^':
  case '|':
  case '~':  goto yy10;
  default:  goto yy12;
  }
yy12:
#line 137 "tokenizer.re.c"
  { TOKENIZER_PUSH_SYMBOL(); continue; }
#line 267 "generated_tokenizer.c"
yy13:
  yyaccept = 1;
  ++offset;
  marker = offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  if (yych <= 0x00) {
    if (offset >= end_offset) goto yy3;
    goto yy37;
  }
  goto yy38;
yy14:
  ++offset;
  goto yy12;
yy15:
  ++offset;
#line 124 "tokenizer.re.c"
  { TOKENIZER_GROUP_START(paren); continue; }
#line 285 "generated_tokenizer.c"
yy17:
  ++offset;
#line 132 "tokenizer.re.c"
  { TOKENIZER_GROUP_END(paren); continue; }
#line 290 "generated_tokenizer.c"
yy19:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case 0x00:  goto yy12;
  case '/':  goto yy42;
  default:  goto yy11;
  }
yy20:
  yyaccept = 2;
  ++offset;
  marker = offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case 'B':
  case 'b':  goto yy44;
  case 'X':
  case 'x':  goto yy45;
  default:  goto yy21;
  }
yy21:
#line 106 "tokenizer.re.c"
  {
        Slice digits = slice_sub(input, token_start_offset, offset);
        TOKENIZER_PUSH_LITERAL(Number_Base_10, digits);
        continue;
      }
#line 318 "generated_tokenizer.c"
yy22:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '0':
  case '1':
  case '2':
  case '3':
  case '4':
  case '5':
  case '6':
  case '7':
  case '8':
  case '9':
  case '_':  goto yy22;
  default:  goto yy21;
  }
yy24:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '0':
  case '1':
  case '2':
  case '3':
  case '4':
  case '5':
  case '6':
  case '7':
  case '8':
  case '9':
  case 'A':
  case 'B':
  case 'C':
  case 'D':
  case 'E':
  case 'F':
  case 'G':
  case 'H':
  case 'I':
  case 'J':
  case 'K':
  case 'L':
  case 'M':
  case 'N':
  case 'O':
  case 'P':
  case 'Q':
  case 'R':
  case 'S':
  case 'T':
  case 'U':
  case 'V':
  case 'W':
  case 'X':
  case 'Y':
  case 'Z':
  case '_':
  case 'a':
  case 'b':
  case 'c':
  case 'd':
  case 'e':
  case 'f':
  case 'g':
  case 'h':
  case 'i':
  case 'j':
  case 'k':
  case 'l':
  case 'm':
  case 'n':
  case 'o':
  case 'p':
  case 'q':
  case 'r':
  case 's':
  case 't':
  case 'u':
  case 'v':
  case 'w':
  case 'x':
  case 'y':
  case 'z':  goto yy24;
  default:  goto yy26;
  }
yy26:
#line 158 "tokenizer.re.c"
  { TOKENIZER_PUSH_SYMBOL(); continue; }
#line 408 "generated_tokenizer.c"
yy27:
  ++offset;
#line 125 "tokenizer.re.c"
  { TOKENIZER_GROUP_START(square); continue; }
#line 413 "generated_tokenizer.c"
yy29:
  ++offset;
#line 133 "tokenizer.re.c"
  { TOKENIZER_GROUP_END(square); continue; }
#line 418 "generated_tokenizer.c"
yy31:
  ++offset;
#line 126 "tokenizer.re.c"
  {
        tokenizer_group_start_curly(
          allocator, &stack, &parent_stack, &descriptor_group_curly, TOKENIZER_CURRENT_RANGE()
        );
        continue;
      }
#line 428 "generated_tokenizer.c"
yy33:
  ++offset;
#line 134 "tokenizer.re.c"
  { TOKENIZER_GROUP_END(curly); continue; }
#line 433 "generated_tokenizer.c"
yy35:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '/':  goto yy46;
  default:  goto yy36;
  }
yy36:
  offset = marker;
  switch (yyaccept) {
  case 0:
    goto yy6;
  case 1:
    goto yy3;
  default:
    goto yy21;
  }
yy37:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
yy38:
  switch (yych) {
  case '"':  goto yy39;
  case '\\':  goto yy41;
  default:
    if (offset >= end_offset) goto yy36;
    goto yy37;
  }
yy39:
  ++offset;
#line 145 "tokenizer.re.c"
  {
        Slice raw_bytes = slice_sub(input, token_start_offset + 1, offset - 1);
        tokenizer_push_string_literal(
          context, &string_buffer, &stack, raw_bytes, TOKENIZER_CURRENT_RANGE()
        );
        continue;
      }
#line 472 "generated_tokenizer.c"
yy41:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  if (yych <= 0x00) {
    if (offset >= end_offset) goto yy36;
    goto yy37;
  }
  goto yy37;
yy42:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '\n':
  case '\r':  goto yy12;
  case '!':
  case '$':
  case '%':
  case '&':
  case '*':
  case '+':
  case ',':
  case '-':
  case '.':
  case '/':
  case ':':
  case '<':
  case '=':
  case '>':
  case '?':
  case '@':
  case '\\':
  case '^':
  case '|':
  case '~':  goto yy42;
  default:
    if (offset >= end_offset) goto yy12;
    goto yy46;
  }
yy44:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '0':
  case '1':
  case '_':  goto yy48;
  default:  goto yy36;
  }
yy45:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '0':
  case '1':
  case '2':
  case '3':
  case '4':
  case '5':
  case '6':
  case '7':
  case '8':
  case '9':
  case 'A':
  case 'B':
  case 'C':
  case 'D':
  case 'E':
  case 'F':
  case '_':
  case 'a':
  case 'b':
  case 'c':
  case 'd':
  case 'e':
  case 'f':  goto yy51;
  default:  goto yy36;
  }
yy46:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '\n':
  case '\r':  goto yy6;
  default:
    if (offset >= end_offset) goto yy6;
    goto yy46;
  }
yy48:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '0':
  case '1':
  case '_':  goto yy48;
  default:  goto yy50;
  }
yy50:
#line 112 "tokenizer.re.c"
  {
        Slice digits = slice_sub(input, token_start_offset + 2, offset);
        TOKENIZER_PUSH_LITERAL(Number_Base_2, digits);
        continue;
      }
#line 575 "generated_tokenizer.c"
yy51:
  ++offset;
  yych = offset < end_offset ? input.bytes[offset] : 0;
  switch (yych) {
  case '0':
  case '1':
  case '2':
  case '3':
  case '4':
  case '5':
  case '6':
  case '7':
  case '8':
  case '9':
  case 'A':
  case 'B':
  case 'C':
  case 'D':
  case 'E':
  case 'F':
  case '_':
  case 'a':
  case 'b':
  case 'c':
  case 'd':
  case 'e':
  case 'f':  goto yy51;
  default:  goto yy53;
  }
yy53:
#line 118 "tokenizer.re.c"
  {
        Slice digits = slice_sub(input, token_start_offset + 2, offset);
        TOKENIZER_PUSH_LITERAL(Number_Base_16, digits);
        continue;
      }
#line 612 "generated_tokenizer.c"
yy54:
#line 101 "tokenizer.re.c"
  { break; }
#line 616 "generated_tokenizer.c"
}
#line 162 "tokenizer.re.c"

  }

  offset++;
  TOKENIZER_GROUP_END(curly);

  if (dyn_array_length(parent_stack)) {
    TOKENIZER_HANDLE_ERROR("Unexpected end of file. Expected a closing brace.");
  }

  #undef TOKENIZER_CURRENT_SLICE
  #undef TOKENIZER_CURRENT_RANGE
  #undef TOKENIZER_HANDLE_ERROR
  #undef TOKENIZER_PUSH_SYMBOL
  #undef TOKENIZER_PUSH_LITERAL

  defer:
  if (result.tag == Mass_Result_Tag_Success) {
    assert(dyn_array_length(stack) == 1);
    Value *root_value = *dyn_array_pop(stack);
    const Group_Curly *root = value_as_group_curly(root_value);
    *out_statements = root->statements;
  }
  fixed_buffer_destroy(string_buffer);
  dyn_array_destroy(stack);
  dyn_array_destroy(parent_stack);
  return result;
}

